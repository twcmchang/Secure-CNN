{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset...\n"
     ]
    }
   ],
   "source": [
    "from utils import CIFAR10, CIFAR100\n",
    "print(\"Reading dataset...\")\n",
    "train_data = CIFAR10(train=True)\n",
    "test_data  = CIFAR10(train=False)\n",
    "\n",
    "Xtrain, Ytrain = train_data.train_data, train_data.train_labels\n",
    "Xtest, Ytest = test_data.test_data, test_data.test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset: %s (50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"training dataset: %s\",Xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "A pure TensorFlow implementation of a neural network. This can be\n",
    "used as a drop-in replacement for a Keras model.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from cleverhans.model import Model\n",
    "\n",
    "\n",
    "class MLP(Model):\n",
    "    \"\"\"\n",
    "    An example of a bare bones multilayer perceptron (MLP) class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layers, input_shape, pretrain_dict=None):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.layer_names = []\n",
    "        self.layers = layers\n",
    "        self.input_shape = input_shape\n",
    "            \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if hasattr(layer, 'name'):\n",
    "                name = layer.name\n",
    "                if (pretrain_dict is not None) and (name in pretrain_dict.keys()):\n",
    "                    if isinstance(layer, BatchNormalization):\n",
    "                        layer.set_input_shape(shape=input_shape,\n",
    "                                              mean=pretrain_dict[name+'_bn_mean'],\n",
    "                                              variance=pretrain_dict[name+'_bn_variance'], \n",
    "                                              gamma=pretrain_dict[name+'_gamma'],\n",
    "                                              beta=pretrain_dict[name+'_beta'])\n",
    "                    else:\n",
    "                        layer.set_input_shape(input_shape,\n",
    "                                              pretrain = pretrain_dict[name])\n",
    "                else:\n",
    "                    layer.set_input_shape(input_shape)\n",
    "            else:\n",
    "                name = layer.__class__.__name__ + str(i)\n",
    "                layer.name = name\n",
    "                layer.set_input_shape(input_shape)\n",
    "            \n",
    "            print(layer.input_shape)\n",
    "            self.layer_names.append(name)\n",
    "            input_shape = layer.get_output_shape()\n",
    "        \n",
    "        if isinstance(layers[-1], Softmax):\n",
    "            layers[-1].name = 'probs'\n",
    "            layers[-2].name = 'logits'\n",
    "            self.layer_names[-1] = 'probs'\n",
    "            self.layer_names[-2] = 'logits'\n",
    "        else:\n",
    "            layers[-1].name = 'logits'\n",
    "            self.layer_names[-1] = 'logits'\n",
    "\n",
    "    def fprop(self, x, set_ref=False):\n",
    "        states = []\n",
    "        for layer in self.layers:\n",
    "            if set_ref:\n",
    "                layer.ref = x\n",
    "            x = layer.fprop(x)\n",
    "            assert x is not None\n",
    "            states.append(x)\n",
    "        states = dict(zip(self.get_layer_names(), states))\n",
    "        return states\n",
    "\n",
    "\n",
    "class Layer(object):\n",
    "\n",
    "    def get_output_shape(self):\n",
    "        return self.output_shape\n",
    "\n",
    "\n",
    "class Linear(Layer):\n",
    "\n",
    "    def __init__(self, num_hid=None, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        self.num_hid = num_hid\n",
    "\n",
    "    def set_input_shape(self, input_shape, pretrain=None):\n",
    "        batch_size, dim = input_shape\n",
    "        if pretrain is None:\n",
    "            if self.num_hid is None: \n",
    "                print(\"Without pre-trained models, please specify num_hid in Linear Layer.\")\n",
    "            init = tf.random_normal([dim, self.num_hid], dtype=tf.float32)\n",
    "            init = init / tf.sqrt(1e-7 + tf.reduce_sum(tf.square(init), axis=0, keep_dims=True))\n",
    "            self.W = tf.Variable(init)\n",
    "            self.b = tf.Variable(np.zeros((self.num_hid,)).astype('float32'))\n",
    "            \n",
    "        else:\n",
    "            self.W = tf.Variable(initial_value = pretrain[0], dtype = tf.float32)\n",
    "            self.b = tf.Variable(initial_value = pretrain[1], dtype = tf.float32)\n",
    "            self.num_hid = len(pretrain[1]) \n",
    "        \n",
    "        self.input_shape = [batch_size, dim]\n",
    "        self.output_shape = [batch_size, self.num_hid]\n",
    "\n",
    "    def fprop(self, x):\n",
    "        return tf.matmul(x, self.W) + self.b\n",
    "\n",
    "\n",
    "class Conv2D(Layer):\n",
    "\n",
    "    def __init__(self, output_channels=None, kernel_shape=None, strides=[1,1], padding='SAME', **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        self.__dict__.update(locals())\n",
    "        del self.self\n",
    "\n",
    "    def set_input_shape(self, input_shape, pretrain=None):\n",
    "        batch_size, rows, cols, input_channels = input_shape\n",
    "        if pretrain is None:\n",
    "            #assert ((self.kernel_shape is None) or (self.output_channels is None)),\\\n",
    "            #        \"Without a pre-trained model, please specify kernel_shape and output_channels in Conv2D layer\"\n",
    "        \n",
    "            kernel_shape = tuple(self.kernel_shape) + (input_channels, self.output_channels)\n",
    "            assert len(kernel_shape) == 4\n",
    "            assert all(isinstance(e, int) for e in kernel_shape), kernel_shape\n",
    "\n",
    "            init = tf.random_normal(kernel_shape, dtype=tf.float32)\n",
    "            init = init / tf.sqrt(1e-7 + tf.reduce_sum(tf.square(init), axis=(0, 1, 2)))\n",
    "            self.kernels = tf.Variable(init)\n",
    "            self.b = tf.Variable(np.zeros((self.output_channels,)).astype('float32'))\n",
    "        else:\n",
    "            self.kernels = tf.Variable(initial_value = pretrain[0], dtype = tf.float32)\n",
    "            self.b = tf.Variable(initial_value = pretrain[1], dtype = tf.float32)\n",
    "            self.kernel_shape = tuple(pretrain[0].shape[:2])\n",
    "            self.output_channels = tuple(pretrain[0].shape[2:3])\n",
    "        self.input_shape = input_shape\n",
    "        input_shape = list(input_shape)\n",
    "        input_shape[0] = 1\n",
    "        dummy_batch = tf.zeros(input_shape)\n",
    "        dummy_output = self.fprop(dummy_batch)\n",
    "        output_shape = [int(e) for e in dummy_output.get_shape()]\n",
    "        output_shape[0] = batch_size\n",
    "        self.output_shape = tuple(output_shape)\n",
    "\n",
    "    def fprop(self, x):\n",
    "        return tf.nn.conv2d(x, self.kernels, (1,) + tuple(self.strides) + (1,),\n",
    "                            self.padding) + self.b\n",
    "\n",
    "\n",
    "class ReLU(Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def set_input_shape(self, shape):\n",
    "        self.input_shape = shape\n",
    "        self.output_shape = shape\n",
    "\n",
    "    def fprop(self, x):\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "class Softmax(Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def set_input_shape(self, shape):\n",
    "        self.input_shape = shape\n",
    "        self.output_shape = shape\n",
    "\n",
    "    def fprop(self, x):\n",
    "        return tf.nn.softmax(x)\n",
    "    \n",
    "class MaxPool(Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def set_input_shape(self, shape):\n",
    "        batch_size, rows, cols, input_channels = shape\n",
    "        input_shape = list(shape)\n",
    "        input_shape[0] = 1\n",
    "        dummy_batch = tf.zeros(input_shape)\n",
    "        dummy_output = self.fprop(dummy_batch)\n",
    "        output_shape = [int(e) for e in dummy_output.get_shape()]\n",
    "        output_shape[0] = batch_size\n",
    "        \n",
    "        self.input_shape = shape\n",
    "        self.output_shape = tuple(output_shape)\n",
    "        \n",
    "    def fprop(self, x):\n",
    "        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "class Flatten(Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def set_input_shape(self, shape):\n",
    "        self.input_shape = shape\n",
    "        output_width = 1\n",
    "        for factor in shape[1:]:\n",
    "            output_width *= factor\n",
    "        self.output_width = output_width\n",
    "        self.output_shape = [shape[0], output_width]\n",
    "\n",
    "    def fprop(self, x):\n",
    "        return tf.reshape(x, [-1, self.output_width])\n",
    "    \n",
    "class BatchNormalization(Layer):\n",
    "    \n",
    "    def __init__(self, dp=1.0, is_train=False, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        self.__dict__.update(locals())\n",
    "        del self.self\n",
    "    \n",
    "    def set_input_shape(self, shape, mean, variance, gamma, beta):\n",
    "        self.input_shape = shape\n",
    "        self.output_shape = shape\n",
    "        self.gamma = tf.Variable(initial_value=gamma)\n",
    "        self.beta = tf.Variable(initial_value=beta)\n",
    "        self.mean = tf.Variable(initial_value=mean)\n",
    "        self.variance = tf.Variable(initial_value=variance)\n",
    "    \n",
    "    def fprop(self, x):\n",
    "        H,W,C,O = x.get_shape().as_list()\n",
    "        n1 = int(O * self.dp)\n",
    "        n0 = O - n1\n",
    "        mask = tf.constant(value=np.append(np.ones(n1, dtype='float32'), np.zeros(n0, dtype='float32')), dtype=tf.float32)\n",
    "        conv_gamma = tf.multiply(self.gamma, mask)\n",
    "        beta = tf.multiply(self.beta, mask)\n",
    "        \n",
    "#         moving_mean = self.mean\n",
    "#         moving_variance = self.variance\n",
    "        \n",
    "#         from tensorflow.python.training.moving_averages import assign_moving_average\n",
    "#         def mean_var_with_update():\n",
    "#             mean, variance = tf.nn.moments(x, [0,1,2], name='moments')\n",
    "#             with tf.control_dependencies([assign_moving_average(tf.cast(moving_mean, tf.float32), mean, 0.9),\n",
    "#                                           assign_moving_average(tf.cast(moving_variance, tf.float32), variance, 0.9)]):\n",
    "#                 return tf.identity(mean), tf.identity(variance)\n",
    "\n",
    "#         self.mean, self.variance = tf.cond(tf.cast(self.is_train, tf.bool), mean_var_with_update, lambda:(moving_mean, moving_variance))\n",
    "\n",
    "        conv = tf.nn.batch_normalization(x, self.mean, self.variance, self.beta, conv_gamma, 1e-05)\n",
    "\n",
    "        return conv\n",
    "\n",
    "\n",
    "def make_basic_cnn(nb_filters=64, nb_classes=10,\n",
    "                   input_shape=(None, 28, 28, 1)):\n",
    "    layers = [Conv2D(output_channels=nb_filters, kernel_shape=(8, 8), strides=(2, 2), padding=\"SAME\"),\n",
    "              ReLU(),\n",
    "              Conv2D(output_channels=nb_filters * 2, kernel_shape=(6, 6), strides=(2, 2), padding=\"SAME\"),\n",
    "              ReLU(),\n",
    "              Conv2D(output_channels=nb_filters * 2, kernel_shape=(5, 5), strides=(1, 1), padding=\"SAME\"),\n",
    "              ReLU(),\n",
    "              Flatten(),\n",
    "              Linear(num_hid=nb_classes),\n",
    "              Softmax()]\n",
    "\n",
    "    model = MLP(layers, input_shape)\n",
    "    return model\n",
    "\n",
    "def make_pretrain_vgg16(input_shape=(None, 28, 28, 1), pretrain_dict=None):\n",
    "    layers = [Conv2D(name='conv1_1'),\n",
    "                ReLU(),\n",
    "                Conv2D(name='conv1_2'),\n",
    "                ReLU(),\n",
    "                Conv2D(name='conv2_1'),\n",
    "                ReLU(),\n",
    "                Conv2D(name='conv2_2'),\n",
    "                ReLU(),\n",
    "                Conv2D(name='conv3_1'),\n",
    "                ReLU(),\n",
    "                Conv2D(name='conv3_2'),\n",
    "                ReLU(),\n",
    "                Conv2D(name='conv3_3'),\n",
    "                ReLU(),\n",
    "                Conv2D(name='conv4_1'),\n",
    "                ReLU(),\n",
    "                Conv2D(name='conv4_2'),\n",
    "                ReLU(),\n",
    "                Conv2D(name='conv4_3'),\n",
    "                ReLU(),\n",
    "                Conv2D(name='conv5_1'),\n",
    "                ReLU(),\n",
    "                Conv2D(name='conv5_2'),\n",
    "                ReLU(),\n",
    "                Conv2D(name='conv5_3'),\n",
    "                ReLU(),\n",
    "                Flatten(),\n",
    "                Linear(name='fc6'),\n",
    "                ReLU(),\n",
    "                Linear(name='fc7'),\n",
    "                ReLU(),\n",
    "                Linear(num_hid=10),\n",
    "                Softmax()]\n",
    "    model = MLP(layers, input_shape,pretrain_dict)\n",
    "    return model\n",
    "\n",
    "def make_reduced_vgg16(input_shape=(None, 28, 28, 1), pretrain_dict=None):\n",
    "    layers = [Conv2D(name='conv1_1'),\n",
    "              BatchNormalization(name='conv1_1'),\n",
    "              ReLU(),\n",
    "              Conv2D(name='conv1_2'),\n",
    "              BatchNormalization(name='conv1_2'),\n",
    "              ReLU(),\n",
    "              MaxPool(),\n",
    "              Conv2D(name='conv2_1'),\n",
    "              BatchNormalization(name='conv2_1'),\n",
    "              ReLU(),\n",
    "              Conv2D(name='conv2_2'),\n",
    "              BatchNormalization(name='conv2_2'),\n",
    "              ReLU(),\n",
    "              MaxPool(),\n",
    "              Conv2D(name='conv3_1'),\n",
    "              BatchNormalization(name='conv3_1'),\n",
    "              ReLU(),\n",
    "              Conv2D(name='conv3_2'),\n",
    "              BatchNormalization(name='conv3_2'),\n",
    "              ReLU(),\n",
    "              Conv2D(name='conv3_3'),\n",
    "              BatchNormalization(name='conv3_3'),\n",
    "              ReLU(),\n",
    "              MaxPool(),\n",
    "              Conv2D(name='conv4_1'),\n",
    "              BatchNormalization(name='conv4_1'),\n",
    "              ReLU(),\n",
    "              Conv2D(name='conv4_2'),\n",
    "              BatchNormalization(name='conv4_2'),\n",
    "              ReLU(),\n",
    "              Conv2D(name='conv4_3'),\n",
    "              BatchNormalization(name='conv4_3'),\n",
    "              ReLU(),\n",
    "              MaxPool(),\n",
    "              Conv2D(name='conv5_1'),\n",
    "              BatchNormalization(name='conv5_1'),\n",
    "              ReLU(),\n",
    "              Conv2D(name='conv5_2'),\n",
    "              BatchNormalization(name='conv5_2'),\n",
    "              ReLU(),\n",
    "              Conv2D(name='conv5_3'),\n",
    "              BatchNormalization(name='conv5_3'),\n",
    "              ReLU(),\n",
    "              MaxPool(),\n",
    "              Flatten(),\n",
    "              Linear(name='fc_1'),\n",
    "              ReLU(),\n",
    "              Linear(name='fc_2'),\n",
    "              Softmax()]\n",
    "    model = MLP(layers, input_shape, pretrain_dict)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse = np.load(\"finetune_dict.npy\",encoding='latin1').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = np.load(\"para_dict.npy\", encoding='latin1').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 32, 32, 3)\n",
      "(None, 32, 32, 36)\n",
      "(None, 32, 32, 36)\n",
      "(None, 32, 32, 36)\n",
      "(None, 32, 32, 56)\n",
      "(None, 32, 32, 56)\n",
      "(None, 32, 32, 56)\n",
      "(None, 16, 16, 56)\n",
      "(None, 16, 16, 93)\n",
      "(None, 16, 16, 93)\n",
      "(None, 16, 16, 93)\n",
      "(None, 16, 16, 105)\n",
      "(None, 16, 16, 105)\n",
      "(None, 16, 16, 105)\n",
      "(None, 8, 8, 105)\n",
      "(None, 8, 8, 150)\n",
      "(None, 8, 8, 150)\n",
      "(None, 8, 8, 150)\n",
      "(None, 8, 8, 140)\n",
      "(None, 8, 8, 140)\n",
      "(None, 8, 8, 140)\n",
      "(None, 8, 8, 150)\n",
      "(None, 8, 8, 150)\n",
      "(None, 8, 8, 150)\n",
      "(None, 4, 4, 150)\n",
      "(None, 4, 4, 116)\n",
      "(None, 4, 4, 116)\n",
      "(None, 4, 4, 116)\n",
      "(None, 4, 4, 37)\n",
      "(None, 4, 4, 37)\n",
      "(None, 4, 4, 37)\n",
      "(None, 4, 4, 17)\n",
      "(None, 4, 4, 17)\n",
      "(None, 4, 4, 17)\n",
      "(None, 2, 2, 17)\n",
      "(None, 2, 2, 17)\n",
      "(None, 2, 2, 17)\n",
      "(None, 2, 2, 17)\n",
      "(None, 2, 2, 15)\n",
      "(None, 2, 2, 15)\n",
      "(None, 2, 2, 15)\n",
      "(None, 2, 2, 36)\n",
      "(None, 2, 2, 36)\n",
      "(None, 2, 2, 36)\n",
      "(None, 1, 1, 36)\n",
      "[None, 36]\n",
      "[None, 512]\n",
      "[None, 512]\n",
      "[None, 10]\n"
     ]
    }
   ],
   "source": [
    "model = make_reduced_vgg16(input_shape=(None,32,32,3),pretrain_dict=sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 32, 32, 3)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 16, 16, 64)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 8, 8, 128)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 4, 4, 256)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 2, 2, 512)\n",
      "(None, 2, 2, 512)\n",
      "(None, 2, 2, 512)\n",
      "(None, 2, 2, 512)\n",
      "(None, 2, 2, 512)\n",
      "(None, 2, 2, 512)\n",
      "(None, 2, 2, 512)\n",
      "(None, 2, 2, 512)\n",
      "(None, 2, 2, 512)\n",
      "(None, 2, 2, 512)\n",
      "(None, 1, 1, 512)\n",
      "[None, 512]\n",
      "[None, 512]\n",
      "[None, 512]\n",
      "[None, 10]\n"
     ]
    }
   ],
   "source": [
    "model = make_reduced_vgg16(input_shape=(None,32,32,3),pretrain_dict=full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import flags\n",
    "import logging\n",
    "\n",
    "from cleverhans.utils_tf import model_train, model_eval\n",
    "from cleverhans.attacks import FastGradientMethod, BasicIterativeMethod\n",
    "from cleverhans.utils import AccuracyReport, set_log_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    'nb_epochs': 1,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on adversarial examples: 0.6103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Object used to keep track of (and return) key accuracies\n",
    "report = AccuracyReport()\n",
    "\n",
    "# Set TF random seed to improve reproducibility\n",
    "tf.set_random_seed(1234)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batch_size = 128\n",
    "\n",
    "    # Define input TF placeholder\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3))\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "    model_path = \"models/\"\n",
    "    \n",
    "    fgsm_params = {'eps': 1,\n",
    "                   'clip_min': 0.,\n",
    "                   'clip_max': 255.}\n",
    "    rng = np.random.RandomState([2017, 8, 30])\n",
    "\n",
    "    preds = model.get_probs(x)\n",
    "    eval_params = {'batch_size': batch_size}\n",
    "    acc = model_eval(sess, x, y, preds, Xtest, Ytest, args=eval_params)\n",
    "    report.clean_train_clean_eval = acc\n",
    "    \n",
    "    fgsm = FastGradientMethod(model, sess=sess)\n",
    "    adv_x = fgsm.generate(x, **fgsm_params)\n",
    "    preds_adv = model.get_probs(adv_x)\n",
    "\n",
    "    eval_par = {'batch_size': batch_size}\n",
    "    acc = model_eval(sess, x, y, preds_adv, Xtest, Ytest, args=eval_par)\n",
    "    print('Test accuracy on adversarial examples: %0.4f\\n' % acc)\n",
    "    report.clean_train_adv_eval = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8819"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.clean_train_clean_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6103"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.clean_train_adv_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     bim = BasicIterativeMethod(model=model, sess=sess)\n",
    "#     bim_params = {'eps':0.1,\n",
    "#                   'eps_iter':1,\n",
    "#                   'clip_min': 0.,\n",
    "#                   'clip_max': 1.}\n",
    "#     adv_x = bim.generate(x, **bim_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 32, 32, 3)\n",
      "(None, 32, 32, 36)\n",
      "(None, 32, 32, 36)\n",
      "(None, 32, 32, 36)\n",
      "(None, 32, 32, 56)\n",
      "(None, 32, 32, 56)\n",
      "(None, 32, 32, 56)\n",
      "(None, 16, 16, 56)\n",
      "(None, 16, 16, 93)\n",
      "(None, 16, 16, 93)\n",
      "(None, 16, 16, 93)\n",
      "(None, 16, 16, 105)\n",
      "(None, 16, 16, 105)\n",
      "(None, 16, 16, 105)\n",
      "(None, 8, 8, 105)\n",
      "(None, 8, 8, 150)\n",
      "(None, 8, 8, 150)\n",
      "(None, 8, 8, 150)\n",
      "(None, 8, 8, 140)\n",
      "(None, 8, 8, 140)\n",
      "(None, 8, 8, 140)\n",
      "(None, 8, 8, 150)\n",
      "(None, 8, 8, 150)\n",
      "(None, 8, 8, 150)\n",
      "(None, 4, 4, 150)\n",
      "(None, 4, 4, 116)\n",
      "(None, 4, 4, 116)\n",
      "(None, 4, 4, 116)\n",
      "(None, 4, 4, 37)\n",
      "(None, 4, 4, 37)\n",
      "(None, 4, 4, 37)\n",
      "(None, 4, 4, 17)\n",
      "(None, 4, 4, 17)\n",
      "(None, 4, 4, 17)\n",
      "(None, 2, 2, 17)\n",
      "(None, 2, 2, 17)\n",
      "(None, 2, 2, 17)\n",
      "(None, 2, 2, 17)\n",
      "(None, 2, 2, 15)\n",
      "(None, 2, 2, 15)\n",
      "(None, 2, 2, 15)\n",
      "(None, 2, 2, 36)\n",
      "(None, 2, 2, 36)\n",
      "(None, 2, 2, 36)\n",
      "(None, 1, 1, 36)\n",
      "[None, 36]\n",
      "[None, 512]\n",
      "[None, 512]\n",
      "[None, 10]\n",
      "Test accuracy on legitimate examples: 0.1000\n",
      "Test accuracy on adversarial examples: 0.1000\n",
      "Test accuracy on legitimate examples: 0.1000\n",
      "Test accuracy on adversarial examples: 0.1000\n",
      "Test accuracy on legitimate examples: 0.1000\n",
      "Test accuracy on adversarial examples: 0.1000\n",
      "Test accuracy on legitimate examples: 0.1000\n",
      "Test accuracy on adversarial examples: 0.1000\n",
      "Test accuracy on legitimate examples: 0.1000\n",
      "Test accuracy on adversarial examples: 0.1000\n",
      "Test accuracy on legitimate examples: 0.1000\n",
      "Test accuracy on adversarial examples: 0.1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-655da8f10647>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     model_train(sess, x, y, preds_2, Xtrain, Ytrain,\n\u001b[1;32m     25\u001b[0m                 \u001b[0mpredictions_adv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreds_2_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 args=train_params, rng=rng)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0meval_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/cleverhans/cleverhans/utils_tf.py\u001b[0m in \u001b[0;36mmodel_train\u001b[0;34m(sess, x, y, predictions, X_train, Y_train, save, predictions_adv, init_all, evaluate, feed, args, rng)\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfeed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                     \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                 \u001b[0mtrain_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Check that all examples were used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m     \"\"\"\n\u001b[0;32m-> 2042\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[0m_gradient_registry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegistry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   4488\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4489\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 4490\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    model_2 = make_reduced_vgg16(input_shape=(None,32,32,3),pretrain_dict=sparse)\n",
    "    preds_2 = model_2(x)\n",
    "    fgsm2 = FastGradientMethod(model_2, sess=sess)\n",
    "    adv_x_2 = fgsm2.generate(x, **fgsm_params)\n",
    "    adv_x_2 = tf.stop_gradient(adv_x_2)\n",
    "    preds_2_adv = model_2(adv_x_2)\n",
    "\n",
    "    def evaluate_2():\n",
    "        # Accuracy of adversarially trained model on legitimate test inputs\n",
    "        eval_params = {'batch_size': batch_size}\n",
    "        accuracy = model_eval(sess, x, y, preds_2, Xtest, Ytest,\n",
    "                              args=eval_params)\n",
    "        print('Test accuracy on legitimate examples: %0.4f' % accuracy)\n",
    "        report.adv_train_clean_eval = accuracy\n",
    "\n",
    "        # Accuracy of the adversarially trained model on adversarial examples\n",
    "        accuracy = model_eval(sess, x, y, preds_2_adv, Xtest,\n",
    "                              Ytest, args=eval_params)\n",
    "        print('Test accuracy on adversarial examples: %0.4f' % accuracy)\n",
    "        report.adv_train_adv_eval = accuracy\n",
    "\n",
    "    # Perform and evaluate adversarial training\n",
    "    model_train(sess, x, y, preds_2, Xtrain, Ytrain,\n",
    "                predictions_adv=preds_2_adv, evaluate=evaluate_2,\n",
    "                args=train_params, rng=rng)\n",
    "\n",
    "    eval_params = {'batch_size': batch_size}\n",
    "    accuracy = model_eval(sess, x, y, preds_2, Xtrain, Ytrain,\n",
    "                          args=eval_params)\n",
    "    report.train_adv_train_clean_eval = accuracy\n",
    "    accuracy = model_eval(sess, x, y, preds_2_adv, Xtrain,\n",
    "                          Ytrain, args=eval_params)\n",
    "    report.train_adv_train_adv_eval = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.adv_train_adv_eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.train_adv_train_adv_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object used to keep track of (and return) key accuracies\n",
    "report = AccuracyReport()\n",
    "\n",
    "# Set TF random seed to improve reproducibility\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    batch_size = 32\n",
    "\n",
    "    # Use label smoothing\n",
    "#     assert Y_train.shape[1] == 10\n",
    "#     label_smooth = .1\n",
    "#     Y_train = Y_train.clip(label_smooth / 9., 1. - label_smooth)\n",
    "\n",
    "    # Define input TF placeholder\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3))\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "    model_path = \"models/\"\n",
    "    # Train an MNIST model\n",
    "#     train_params = {\n",
    "#         'nb_epochs': nb_epochs,\n",
    "#         'batch_size': batch_size,\n",
    "#         'learning_rate': learning_rate\n",
    "#     }\n",
    "    fgsm_params = {'eps': 0.3,\n",
    "                   'clip_min': 0.,\n",
    "                   'clip_max': 1.}\n",
    "    rng = np.random.RandomState([2017, 8, 30])\n",
    "\n",
    "#     if clean_train:\n",
    "#         model = make_basic_cnn(nb_filters=nb_filters)\n",
    "#         preds = model.get_probs(x)\n",
    "\n",
    "#         def evaluate():\n",
    "#             # Evaluate the accuracy of the MNIST model on legitimate test\n",
    "#             # examples\n",
    "#             eval_params = {'batch_size': batch_size}\n",
    "#             acc = model_eval(\n",
    "#                 sess, x, y, preds, X_test, Y_test, args=eval_params)\n",
    "#             report.clean_train_clean_eval = acc\n",
    "#             assert X_test.shape[0] == test_end - test_start, X_test.shape\n",
    "#             print('Test accuracy on legitimate examples: %0.4f' % acc)\n",
    "#         model_train(sess, x, y, preds, X_train, Y_train, evaluate=evaluate,\n",
    "#                     args=train_params, rng=rng)\n",
    "\n",
    "        # Calculate training error\n",
    "#         if testing:\n",
    "    preds = model.get_probs(x)\n",
    "    eval_params = {'batch_size': batch_size}\n",
    "    acc = model_eval(\n",
    "        sess, x, y, preds, Xtrain, Ytrain, args=eval_params)\n",
    "    report.train_clean_train_clean_eval = acc\n",
    "\n",
    "        # Initialize the Fast Gradient Sign Method (FGSM) attack object and\n",
    "        # graph\n",
    "        fgsm = FastGradientMethod(model, sess=sess)\n",
    "        adv_x = fgsm.generate(x, **fgsm_params)\n",
    "        preds_adv = model.get_probs(adv_x)\n",
    "\n",
    "        # Evaluate the accuracy of the MNIST model on adversarial examples\n",
    "        eval_par = {'batch_size': batch_size}\n",
    "        acc = model_eval(sess, x, y, preds_adv, X_test, Y_test, args=eval_par)\n",
    "        print('Test accuracy on adversarial examples: %0.4f\\n' % acc)\n",
    "        report.clean_train_adv_eval = acc\n",
    "\n",
    "        # Calculate training error\n",
    "        if testing:\n",
    "            eval_par = {'batch_size': batch_size}\n",
    "            acc = model_eval(sess, x, y, preds_adv, X_train,\n",
    "                             Y_train, args=eval_par)\n",
    "            report.train_clean_train_adv_eval = acc\n",
    "\n",
    "        print(\"Repeating the process, using adversarial training\")\n",
    "    # Redefine TF model graph\n",
    "    model_2 = make_basic_cnn(nb_filters=nb_filters)\n",
    "    preds_2 = model_2(x)\n",
    "    fgsm2 = FastGradientMethod(model_2, sess=sess)\n",
    "    adv_x_2 = fgsm2.generate(x, **fgsm_params)\n",
    "    if not backprop_through_attack:\n",
    "        # For the fgsm attack used in this tutorial, the attack has zero\n",
    "        # gradient so enabling this flag does not change the gradient.\n",
    "        # For some other attacks, enabling this flag increases the cost of\n",
    "        # training, but gives the defender the ability to anticipate how\n",
    "        # the atacker will change their strategy in response to updates to\n",
    "        # the defender's parameters.\n",
    "        adv_x_2 = tf.stop_gradient(adv_x_2)\n",
    "    preds_2_adv = model_2(adv_x_2)\n",
    "\n",
    "    def evaluate_2():\n",
    "        # Accuracy of adversarially trained model on legitimate test inputs\n",
    "        eval_params = {'batch_size': batch_size}\n",
    "        accuracy = model_eval(sess, x, y, preds_2, X_test, Y_test,\n",
    "                              args=eval_params)\n",
    "        print('Test accuracy on legitimate examples: %0.4f' % accuracy)\n",
    "        report.adv_train_clean_eval = accuracy\n",
    "\n",
    "        # Accuracy of the adversarially trained model on adversarial examples\n",
    "        accuracy = model_eval(sess, x, y, preds_2_adv, X_test,\n",
    "                              Y_test, args=eval_params)\n",
    "        print('Test accuracy on adversarial examples: %0.4f' % accuracy)\n",
    "        report.adv_train_adv_eval = accuracy\n",
    "\n",
    "    # Perform and evaluate adversarial training\n",
    "    model_train(sess, x, y, preds_2, X_train, Y_train,\n",
    "                predictions_adv=preds_2_adv, evaluate=evaluate_2,\n",
    "                args=train_params, rng=rng)\n",
    "\n",
    "    # Calculate training errors\n",
    "    if testing:\n",
    "        eval_params = {'batch_size': batch_size}\n",
    "        accuracy = model_eval(sess, x, y, preds_2, X_train, Y_train,\n",
    "                              args=eval_params)\n",
    "        report.train_adv_train_clean_eval = accuracy\n",
    "        accuracy = model_eval(sess, x, y, preds_2_adv, X_train,\n",
    "                              Y_train, args=eval_params)\n",
    "        report.train_adv_train_adv_eval = accuracy\n",
    "\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
